---
title: "Final Assignment - KNN Model"
author: "Ricardo Lu"
date: '2022-07-18'
output: 
    html_document:
      toc: yes 
      toc_float: yes
      theme: readable
---

**Set up**
```{r warning = FALSE, message = FALSE}
library(tidyverse)
library(tidymodels)
library(doParallel)
library(knitr)
library(GGally)
library(scales)
library(tictoc)
library(kernlab)
```
# Modeling Experiments

### Load Data
```{r}
Default<-read.csv('default of credit card clients - adapted.csv')
```


### Define Metrics

To measure performance, we have following metrics: ROC AUC, accuracy, precision, and recall. ROC AUC is the optimization metric.

```{r}
my_metrics <- metric_set(roc_auc,accuracy,precision,recall)
```

### Split Data
  
split the data with 70% for training and 30x`% for testing Stratify on customers' default status. 

```{r}

set.seed(1267)
default_split <- initial_split(Default, prop = 0.70, 
                              strata = is_default)
default_train <- training(default_split)
default_test <- testing(default_split)

```

### Create the Resamples

For cross validation, we used 5-fold cross validation with 5 repetition. It means that we divided the data set into 5 subsets, out of these folds, one subset is used as a validation set, and rest others are involved in training the model. We repeats the process for 5 times of splitting the data into k-folds

```{r}
set.seed(1342)
default_folds <- default_train %>%
    vfold_cv(v = 5, repeats = 5, strata = is_default)
```

# Construct workflow


### Preprocessing recipe
```{r}
 knn_recipe_base<-
   recipe(is_default ~ ., data = default_train) %>% 
   step_zv(all_numeric_predictors()) %>% 
    step_YeoJohnson(all_numeric_predictors()) %>% 
   step_normalize(all_numeric_predictors()) %>% 
   step_dummy(all_nominal_predictors())  %>% 
  step_corr(all_numeric_predictors())


knn_recipe_enhanced<-knn_recipe_base %>% 
  step_mutate_at(matches('_amount[1-6]'), fn = as.numeric) %>%
  step_mutate_at(matches('pay_[0-6]'), fn = as.numeric) %>%
   step_mutate(
       bill_amount_credit1 = bill_amount1 < 0,
         bill_amount_credit2 = bill_amount2 < 0,
         bill_amount_credit3 = bill_amount3 < 0,
         bill_amount_credit4 = bill_amount4 < 0,
         bill_amount_credit5 = bill_amount5 < 0,
         bill_amount_credit6 = bill_amount6 < 0,
         pay_status1 = pay_0 < 0,
         pay_status2 = pay_2 < 0,
         pay_status3 = pay_3 < 0,
         pay_status4 = pay_4 < 0,
         pay_status5 = pay_5 < 0,
        pay_status6 = pay_6 < 0,
         repayment = sum(pay_amount1,pay_amount2,pay_amount3,pay_amount4,pay_amount5,pay_amount6)/sum(bill_amount1,bill_amount2,bill_amount3,bill_amount4,bill_amount5,bill_amount6)) %>%
    step_mutate_at(matches('credit'), fn = as.numeric) %>%
    step_mutate_at(matches('bill_amount[1-6]'), fn = ~ if_else(. < 0, 0, .)) %>%
    step_mutate_at(matches('status'), fn = as.numeric) %>%
    step_mutate_at(matches('pay[0-6]'), fn = ~ if_else(. < 0, 0, .))

 
```

### Model
```{r}
knn_model <-
    nearest_neighbor(neighbors = tune()) %>%
    set_mode(('classification')) %>%
    set_engine('kknn')  


knn_grid <- grid_latin_hypercube(
    neighbors(),
    size = 25)


```

### Define the workflow
```{r}
knn_wf_base <-
    workflow() %>%
    add_recipe(knn_recipe_base) %>%
    add_model(knn_model)


knn_wf_enhanced <-
    workflow() %>%
    add_recipe(knn_recipe_enhanced) %>%
    add_model(knn_model)

```

**Setup Parallelization**
```{r}
library(doParallel)

number_of_cores <- parallel::detectCores(logical = FALSE)
cluster <- makePSOCKcluster(number_of_cores)
registerDoParallel(cluster)
```
# Tune the first model


```{r warning = FALSE, Message = FALSE}
knn_control <- control_resamples(save_pred = TRUE)


tic()

knn_results_base <-
    knn_wf_base %>%
    tune_grid(
        default_folds,
        grid = knn_grid,
        metrics = my_metrics,
        control = knn_control
    )

toc()

```

**Stop Parallelization**

```{r}
stopCluster(cluster)
```


### Collecting the Performance Metrics


```{r}

knn_metrics_base <- knn_results_base %>%
    collect_metrics() %>% 
      mutate(recipe = 'Base')

knn_metrics_base
```

```{r}

knn_base_roc <- knn_results_base %>%
    show_best(metric = 'roc_auc') %>% 
  mutate(Metric = "Roc Auc")

knn_base_accuracy <- knn_results_base %>%
    show_best(metric = 'accuracy')%>% 
  mutate(Metric = "Accuracy")

knn_base_precision <- knn_results_base %>%
    show_best(metric = 'precision')%>%
  mutate(Metric = "Precision") 

knn_base_recall <- knn_results_base %>%
    show_best(metric = 'recall')%>% 
  mutate(Metric = "Recall") 

knn_best_base <- bind_rows(knn_base_roc,knn_base_accuracy,knn_base_precision,knn_base_accuracy) %>% 
  kable(digits = 3,
        caption = "Performance metric - Base knn")
knn_best_base
```

* Model with base recipe has the highest roc auc value of 0.711.

**Setup Parallelization**

```{r}
library(doParallel)

number_of_cores <- parallel::detectCores(logical = FALSE)
cluster <- makePSOCKcluster(number_of_cores)
registerDoParallel(cluster)

```

# Tune the second model

```{r warning = FALSE, Message = FALSE}
knn_control <- control_resamples(save_pred = TRUE)


tic()

knn_results_enhanced <-
    knn_wf_enhanced %>%
    tune_grid(
        default_folds,
        grid = knn_grid,
        metrics = my_metrics,
        control = knn_control
    )

toc()

```
**Stop Parallelization**

```{r}
stopCluster(cluster)
```


### Collecting the Performance Metrics


```{r}

knn_metrics_enhanced <- knn_results_enhanced %>%
    collect_metrics() %>% 
      mutate(recipe = 'Enhanced')

knn_metrics_enhanced
```

```{r}

knn_enhanced_roc <- knn_results_enhanced %>%
    show_best(metric = 'roc_auc') %>% 
  mutate(Metric = "Roc Auc")

knn_enhanced_accuracy <- knn_results_enhanced %>%
    show_best(metric = 'accuracy')%>% 
  mutate(Metric = "Accuracy")

knn_enhanced_precision <- knn_results_enhanced %>%
    show_best(metric = 'precision')%>%
  mutate(Metric = "Precision") 

knn_enhanced_recall <- knn_results_enhanced %>%
    show_best(metric = 'recall')%>% 
  mutate(Metric = "Recall") 

knn_best_enhanced <- bind_rows(knn_enhanced_roc,knn_enhanced_accuracy,knn_enhanced_precision,knn_enhanced_accuracy) %>% 
  kable(digits = 3,
        caption = "Performance metric - Enhanced knn")
knn_best_enhanced
```

* Model with enhanced recipe has highest value of 0.699, which could result from the feautre of KNN model that it do not work very well with large data set, given the fact that many variables are created in the enhanced recipe. 


# Tune the thrid model

**Setup Parallelization**
```{r}
library(doParallel)

number_of_cores <- parallel::detectCores(logical = FALSE)
cluster <- makePSOCKcluster(number_of_cores)
registerDoParallel(cluster)
```

```{r warning = FALSE, Message = FALSE}
knn_grid2 <- grid_regular(neighbors(range = c(3, 50)), 
                         levels = 10)

knn_control <- control_resamples(save_pred = TRUE)


tic()

knn_results_best <-
    knn_wf_base %>%
    tune_grid(
        default_folds,
        grid = knn_grid2,
        metrics = my_metrics,
        control = knn_control
    )

toc()
```

**Stop Parallelization**

```{r}
stopCluster(cluster)
```

### Collecting the Performance Metrics


```{r}

knn_metrics_best <- knn_results_best %>%
    collect_metrics() 

knn_metrics_best
```

```{r}

knn_best_roc <- knn_results_best %>%
    show_best(metric = 'roc_auc') %>% 
  mutate(Metric = "Roc Auc")

knn_best_accuracy <- knn_results_best %>%
    show_best(metric = 'accuracy')%>% 
  mutate(Metric = "Accuracy")

knn_best_precision <- knn_results_best %>%
    show_best(metric = 'precision')%>%
  mutate(Metric = "Precision") 

knn_best_recall <- knn_results_best %>%
    show_best(metric = 'recall')%>% 
  mutate(Metric = "Recall") 

knn_best <- bind_rows(knn_best_roc,knn_best_accuracy,knn_best_precision,knn_best_accuracy) %>% 
  kable(digits = 3,
        caption = "Performance metric - best knn")
knn_best
```
* After redefining the parameter, the model with enhhanced recipe has the highest roc auc value of 0.746. 

# Conclude the Experiment

## Confusion Matrix

### Select an optimal model

  
we selected the least complex model that is still within one standard error from the best-performing model.
  
```{r}
knn_by_std_err <- knn_results_best %>%
    select_by_one_std_err(metric = 'roc_auc', neighbors)

knn_by_std_err %>%
    kable(digits = 3,
          caption = 'Optimal Model after Adjusting by Standard Error')
```
  
```{r}
conf_knn <- knn_results_best %>%
  conf_mat_resampled(parameters = knn_by_std_err)

conf_knn %>%
  kable()

```

### Finalize the workflow
```{r}
final_workflow_knn<-knn_wf_base %>% 
  finalize_workflow(knn_by_std_err)
```

## Save results to external files

```{r}
save(knn_by_std_err,conf_knn,knn_metrics_best,knn_best_enhanced,knn_best_base,knn_wf_base,final_workflow_knn,file = 'knn.Rda')
```